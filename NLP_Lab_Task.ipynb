{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7us--hm-R_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca3d261f-2fb2-45d3-bd76-8729f3ceb6c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**"
      ],
      "metadata": {
        "id": "u19I9guXBdoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"She sings beautifully at the concert\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "3uv7hOWLA3Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62895e7-3f83-4091-a2b5-6760e843ca28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['She', 'sings', 'beautifully', 'at', 'the', 'concert']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**"
      ],
      "metadata": {
        "id": "ykLMu-BpBgLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "words = [\"She\", \"sings\", \"beautifully\", \"at\", \"the\", \"concert\"]\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm5RmO9sBbWN",
        "outputId": "a2db0e93-9411-4481-d0c9-2ebaa9718e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['she', 'sing', 'beauti', 'at', 'the', 'concert']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Morphemes Identification**"
      ],
      "metadata": {
        "id": "k2OVXpGtCCX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_morphemes(word):\n",
        "    morphemes = []\n",
        "    prefix = word[:2]\n",
        "    root = word[2:-2]\n",
        "    suffix = word[-2:]\n",
        "    morphemes.append(prefix)\n",
        "    morphemes.append(root)\n",
        "    morphemes.append(suffix)\n",
        "    return morphemes\n",
        "\n",
        "word = \"undoable\"\n",
        "morphemes = identify_morphemes(word)\n",
        "print(\"Morphemes:\", morphemes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc86OSPPB3MT",
        "outputId": "d67bc96d-d692-4565-a606-1e7faa3da1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Morphemes: ['un', 'doab', 'le']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parse Tree**"
      ],
      "metadata": {
        "id": "1J-qHUUFCZU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_morphology(word):\n",
        "    parse_tree = {}\n",
        "    parse_tree['prefix'] = word[:2]\n",
        "    parse_tree['root'] = word[2:-2]\n",
        "    parse_tree['suffix'] = word[-2:]\n",
        "    return parse_tree\n",
        "\n",
        "word = \"inactive\"\n",
        "parse_tree = parse_morphology(word)\n",
        "print(\"Parse Tree:\", parse_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfIOlfzhCHWr",
        "outputId": "33ac9f5b-c686-40a9-f8ed-a6f15b4d80c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse Tree: {'prefix': 'in', 'root': 'acti', 'suffix': 've'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Morpheme Frequencies**"
      ],
      "metadata": {
        "id": "vFfDDznNDB5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "corpus = [\"redo\", \"unnatural\", \"outcome\", \"understandable\"]\n",
        "\n",
        "def identify_morphemes(word):\n",
        "    prefix = word[:2]\n",
        "    suffix = word[-2:]\n",
        "    return prefix, suffix\n",
        "\n",
        "morpheme_counts = Counter()\n",
        "for word in corpus:\n",
        "    prefix, suffix = identify_morphemes(word)\n",
        "    morpheme_counts[prefix] += 1\n",
        "    morpheme_counts[suffix] += 1\n",
        "\n",
        "print(\"Morpheme Frequencies:\")\n",
        "for morpheme, count in morpheme_counts.items():\n",
        "    print(f\"{morpheme}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-WSJcqaCa_T",
        "outputId": "e62fa961-8e60-48a4-9557-d3c9632078a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Morpheme Frequencies:\n",
            "re: 1\n",
            "do: 1\n",
            "un: 2\n",
            "al: 1\n",
            "ou: 1\n",
            "me: 1\n",
            "le: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overstemming Error & Correction**"
      ],
      "metadata": {
        "id": "QgC5JFguDxbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_overstemming(word):\n",
        "    if word.endswith(\"ing\") or word.endswith(\"ly\"):\n",
        "        corrected_word = word[:-2]\n",
        "    else:\n",
        "        corrected_word = word\n",
        "    return corrected_word\n",
        "\n",
        "words = [\"running\",\"quickly\",\"happily\", \"friendship\"]\n",
        "\n",
        "corrected_words = [correct_overstemming(word) for word in words]\n",
        "\n",
        "print(\"Corrected Words:\", corrected_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXVqQaC4DE0j",
        "outputId": "7426b1ee-c5b9-44ae-a48e-4149e7b63af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected Words: ['runni', 'quick', 'happi', 'friendship']\n"
          ]
        }
      ]
    }
  ]
}